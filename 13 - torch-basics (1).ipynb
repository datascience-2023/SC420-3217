{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a845243-e424-4e4f-97f0-4623283c9548",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Нейронные сети на базе PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4300357d-1805-42bc-a40a-dfe53fee94c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchinfo\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchinfo\n",
    "\n",
    "import timm\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f84bbf-28ee-4b90-b936-02fd759f7d25",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e92186-eb03-430a-bb5d-338d4c7b351f",
   "metadata": {},
   "source": [
    "Мы воспользуемся датасетом MNIST с рукописными цифрами из комплекта torchvision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd9484-f4bd-4422-824b-17dc91b7b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST('mnist-data', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5addff5-a6b1-4f0e-a651-e3a0f6eafc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c15656e-45cf-4190-a503-a3363cc76aa4",
   "metadata": {},
   "source": [
    "Изначально он содежит картинки в формате PIL, но мы воспользуемся встроенным преобразованием, чтобы получать сразу массивы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bf9503-1c73-4ce1-b830-c222307cb82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST('mnist-data', download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafd309c-0668-482a-a728-d18f2e28f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1980470-2491-447a-be1a-cdfa2dba426b",
   "metadata": {},
   "source": [
    "## Тензоры и автоматическое дифференцирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2827b8f8-3bd4-40fd-9d93-2a6f9daaa197",
   "metadata": {},
   "source": [
    "Попробуем распознавать символы линейно (то есть kX+b).\n",
    "\n",
    "На входе будет картинка 28х28, а на выходе 10 классов. Поскольку наш алгоритм линейный, картинку придется сплющить в один вектор длиной 28х28=784. Получается матрица весов 784х10. Заполним ее случайными значениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275a5365-0807-4f3c-bb1b-9c795704685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.randn(28 * 28, 10) / 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5f07a3-3de3-448d-b405-ed484deb9e35",
   "metadata": {},
   "source": [
    "Это так называемая инициализация Ксавье: случайные числа из стандартного нормального распределения, поделенные на корень из размера входных данных.\n",
    "\n",
    "Важное свойство тензоров torch - возможность автоматического подсчета градиента. Как только мы объявим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d266d6-36dd-4a6d-838f-f7d3f3c434ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aa6801-a383-4d36-8008-e59f8560a443",
   "metadata": {},
   "source": [
    "все действия над тензором будут учитываться для будущего расчета градиента."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1746fe78-e568-4d1b-8065-7fc49d9049a7",
   "metadata": {},
   "source": [
    "Не забудем задать и вектор смещения (его можно инициализировать нулями)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6395fffe-3ae5-4482-b1c3-3db8a2e49fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1e6c39-bc7c-42f0-ab72-4c7dab139bae",
   "metadata": {},
   "source": [
    "Для бинарной классификации мы пропускали результаты линейной регрессии через логистическую функцию. В случае мультикласса нам понадобится ее обобщение - **softmax**\n",
    "\n",
    "$$\n",
    "Softmax(x_i) = \\frac{e^{x_i}}{\\sum_j {e^{x_j}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5057ad-eae9-4a12-b492-4a79a4ae8ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    return torch.softmax(x @ weights + bias, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e557af68-5e3e-4a33-bd74-5e7d8aec6338",
   "metadata": {},
   "source": [
    "Стоит сразу подумать и о потреблении ресурсов. Как правило, при обучении нейросетей пользуются стохастическим градиентным спуском - обучают небольшими порциями (batch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079c8c03-e078-4df5-81d3-45332bc0da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "xb = torch.stack([dataset[i][0].flatten() for i in range(batch_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452ace2f-0f71-4165-88a9-33e38a7cbf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6541b76c-1db9-48f6-b39c-b4a024225f3f",
   "metadata": {},
   "source": [
    "Теперь, когда мы передадим модели этот пакет данных, мы получим на выходе матрицу 64х10 - вероятности класса для каждого элемента в батче:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b81e7b-a2f2-404d-b2cd-40e70dab95fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(xb)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b33c58-c292-447a-82a0-bc8bc861e858",
   "metadata": {},
   "source": [
    "В случае мультикласса порог не так важен: где вероятность больше, тот класс и предсказываем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d06c43d-e831-4ac5-9fa8-ec703e673711",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.argmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de67485-40b4-4eff-b9df-33924c361811",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da6309f-e3a0-493c-9160-1e385d8c10c4",
   "metadata": {},
   "source": [
    "Можно сразу оценить и метрику accuracy (она, естественно, будет околонулевая, поскольку мы еще ничего не учили)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7b5b65-8108-475b-84b8-857aa96fa371",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = torch.as_tensor([dataset[i][1] for i in range(batch_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46329c46-303b-4b08-86be-4dd49ee54573",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ce3750-1e5f-46dc-b9f8-694059fe4c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "(preds == y_true).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85027725-8af4-4012-8329-432eee19899e",
   "metadata": {},
   "source": [
    "### А как учиться?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e682ef7d-8793-41da-b930-6ec87d0d4650",
   "metadata": {},
   "source": [
    "Вспоминаем, что нам надо минимизировать функцию потерь. В случае классификации это logloss. В torch она реализована как `torch.nn.NLLLoss()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3536ba04-a86f-4bf0-a298-9eb02f2f8ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.NLLLoss()\n",
    "loss = loss_func(output, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badbdf16-0997-4dbb-ad32-81d1435d12f4",
   "metadata": {},
   "source": [
    "Вот тут в дело и вступает автоматическое дифференцирование! Для этого нам нужно сделать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00342802-04f2-4fb8-943e-79893c40d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570f6b44-0b70-4125-8e11-0c056388c91e",
   "metadata": {},
   "source": [
    "А затем остается соответственно сдвинуть веса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b22177f-5256-4bc9-9494-7148d4e31b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61550f12-6416-4588-89fd-c68fa0c95280",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    weights -= weights.grad * learning_rate\n",
    "    bias -= bias.grad * learning_rate\n",
    "    weights.grad.zero_()\n",
    "    bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4e3aac-b886-481a-b723-b9526f4ead48",
   "metadata": {},
   "source": [
    "В конце использованный градиент мы сбрасывем и начинаем следующую итерацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479eb51f-9d0d-449d-86ac-402da689bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe35d84-50fe-4074-ad1d-1ec5a6bf6424",
   "metadata": {},
   "source": [
    "Оформляем обучение в виде цикла:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d047a9d6-1646-490c-858e-2f7facfd3e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(10)):\n",
    "    for i in range(len(dataset) // batch_size):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        xb = torch.stack([dataset[i][0].flatten() for i in range(start, end)])\n",
    "        yb = y_true = torch.as_tensor([dataset[i][1] for i in range(start, end)])\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * learning_rate\n",
    "            bias -= bias.grad * learning_rate\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c9c38-52c6-4e29-8967-f214e9907644",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy на последнем батче: {(pred.argmax(axis=1) == yb).float().mean().item():.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd8fa49-5b6a-4e56-979e-6d9d1a0bd8a5",
   "metadata": {},
   "source": [
    "## Удобства torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cec6ad2-6034-4bbe-9e41-252ec419c109",
   "metadata": {},
   "source": [
    "В реальных задачах нам не нужно вручную задавать тензоры и перемножать их. Torch содержит реализации всевозможных слоев, нам нужно только написать класс, наследующий `torch.nn.Module` и реализовать в нем метод `forward()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b9871-bb0f-466d-ba16-7d65dd226a73",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48f7d8c-b178-4640-99f1-ce483ee81b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.lin = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = self.flatten(xb)\n",
    "        return self.lin(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0d3cdf-e919-422b-978b-ba1ef01a3378",
   "metadata": {},
   "source": [
    "Не обязательно и делать руками логистику на выходе: есть функция потерь `CrossEntropyLoss()`, применяющая ее автоматически:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae8cb7e-9b48-4e26-a73b-4bde071e0813",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f661bc4a-0e00-45c1-93fe-d9f0e1c7f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(10)):\n",
    "    for i in range(len(dataset) // batch_size):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        xb = torch.stack([dataset[i][0] for i in range(start, end)])\n",
    "        yb = y_true = torch.as_tensor([dataset[i][1] for i in range(start, end)])\n",
    "        \n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for p in model.parameters():\n",
    "                p -= p.grad * learning_rate\n",
    "            model.zero_grad()\n",
    "print(f'Accuracy на последнем батче: {(pred.argmax(axis=1) == yb).float().mean().item():.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66ba764-81f8-4d37-8402-773ec3861b5a",
   "metadata": {},
   "source": [
    "### Оптимизаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1786a976-4203-4d86-bca7-c554fd44c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8b8c10-ee6d-4f84-af92-a5f9687cdf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d54c29-c377-428b-9c37-00e0224b8a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_func):\n",
    "    for epoch in tqdm(range(10)):\n",
    "        for i in range(len(dataset) // batch_size):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            xb = torch.stack([dataset[i][0] for i in range(start, end)])\n",
    "            yb = y_true = torch.as_tensor([dataset[i][1] for i in range(start, end)])\n",
    "            \n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    print(f'Accuracy на последнем батче: {(pred.argmax(axis=1) == yb).float().mean().item():.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ef805b-1929-4b0e-b2da-7b2fd71e705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optimizer, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4633316-7614-4571-84ec-35381e638e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "train(model, optimizer, loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccad0ee5-04aa-46eb-b08e-a051de80c243",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f204bb-6a54-4f15-a6fd-28aaf48d4bd0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a315ab-a1a9-4628-b202-2b5c6814f779",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4d7d0a-c38b-49a0-9097-109d829a63af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_func):\n",
    "    for epoch in tqdm(range(10)):\n",
    "        for xb, yb in train_dl:\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    print(f'Accuracy на последнем батче: {(pred.argmax(axis=1) == yb).float().mean().item():.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac9cf4e-08b1-435d-8405-a108fa13288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "optimizer = Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "train(model, optimizer, loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac7b368-a0df-4960-a63f-b698a2e5e9b9",
   "metadata": {},
   "source": [
    "## Добавляем валидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af63cb0f-113f-427a-b942-0e688035092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80c1afa-6e92-4c1f-8c4c-e60d8dfe92ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(177013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87a6d43-88dc-4913-a0a9-8f3d93db7e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = random_split(dataset, [0.8, 0.2], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f114a-2f33-4663-a2f8-79a751089fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_dl = DataLoader(test_set, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a55aece-309c-4c3b-adfa-a344e996bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "optimizer = Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1492d718-0a89-478e-b89a-8cfddaa0a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_func, num_epochs=10):\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for xb, yb in train_dl:\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6617787a-bae2-4b26-8693-752a440c44c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    accuracies = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_dl:\n",
    "            pred = model(xb)\n",
    "            accuracies.append((pred.argmax(axis=1) == yb).float().mean().item())\n",
    "    print(f'Accuracy на валидации: {torch.mean(torch.as_tensor(accuracies)):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f7b9c9-6870-46fe-8c60-548865bcf8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optimizer, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b84c27a-e639-4be9-8cb8-0f15acef79d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70871cfd-b074-4e2e-a791-e8603acbcd54",
   "metadata": {},
   "source": [
    "## Полносвязная сеть с несколькими слоями"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5e19eb-b775-4928-89a6-56d3d394e68c",
   "metadata": {},
   "source": [
    "Еще один вариант задать сложную сеть - с помощью контейнера `torch.nn.Sequential()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8e56c0-cae1-404d-898b-d2587b999269",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(784, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 10),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62f4c0f-84bc-4975-ab85-cb9ee0a83021",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1b8975-216b-43c3-946f-5181a8c6c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optimizer, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1361a46e-90e2-4c5c-a918-038155fe87e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388a6522-fdc9-426c-ad67-edc73e6944aa",
   "metadata": {},
   "source": [
    "## Свертка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e772f72-fc62-4922-a69e-fd1ee36d74b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c48f8d0-0226-46f6-a25f-f76c795d824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = Image.open('photo_2023-01-23_21-07-07.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23405659-757c-4a61-8c60-031c7cfd228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = pic.resize((256,320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d5fb25-583c-4bc0-b242-5dffb5400fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737257ac-195a-4153-a9ee-d407b9ddc820",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c371fa-0c7a-415e-b25b-1a05c11d7e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [ \n",
    "             [[0, 0, 0],  \n",
    "              [0, 1, 0],\n",
    "              [0, 0, 0]],\n",
    "    \n",
    "             [[0, -1, 0],\n",
    "              [-1, 5, -1],\n",
    "              [0, -1, 0]],\n",
    "    \n",
    "             [[0, 0, 0],\n",
    "              [1, -2, 1],\n",
    "              [0, 0, 0]],\n",
    "    \n",
    "             [[0, 1, 0],\n",
    "              [0, -2, 0],\n",
    "              [0, 1, 0]],\n",
    "    \n",
    "             [[0, 1, 0],\n",
    "              [1, -4, 1],\n",
    "              [0, 1, 0]],\n",
    "    \n",
    "             [[-1, 0, 1],\n",
    "              [-2, 0, 2],\n",
    "              [-1, 0, 1]],\n",
    "    \n",
    "            [[-1, -2, -1],\n",
    "             [0,   0,  0],\n",
    "             [1,   2,  1]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575ef4cf-7cd9-4d70-907a-8592e6571b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,3, figsize=(10, 10))\n",
    "for kernel, ax in zip(kernels, axes.flat):\n",
    "    result = np.array([convolve2d(data[:,:,i], kernel, mode='same') for i in range(3)]).transpose((1,2,0))\n",
    "    ax.imshow(result, vmin=0, vmax=255);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b29b3d-2932-4927-9ca9-c2113825d8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97ac1e62-b4a7-40b1-92fd-d031f02a2fc0",
   "metadata": {},
   "source": [
    "### Модель классификации на базе сверток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5000471c-16be-49d9-9a52-c6401e7cca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(6, 16, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(784, 120),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(120, 84),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(84, 10),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7773e26-4d23-405e-a9a3-fc5e12b6ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02df0fdb-f49c-4aaf-8df3-c19e3c3082b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd10cbe-6a42-422c-9043-5ba53a85e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optimizer, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f833daa-824a-4820-ace9-eab0c3e2d22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ac6eda-1a16-461f-997a-6639741e626d",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02107cb1-7bb5-47df-b4a8-257298dd6573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c60875d-b332-4540-9aed-983e23fb3b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(weights='IMAGENET1K_V1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b190d741-a9f1-4d53-84fa-f74775aa4752",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00d0b61-386a-4983-a63d-ec8446a7bb1c",
   "metadata": {},
   "source": [
    "### Меняем слои вручную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb9ebd9-fa32-4df8-b252-581ab3f1e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f58e4f-f47d-4e0b-bece-b14dde5c68b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(model.fc.in_features, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b4d59d-544a-420b-a0ec-ee07e690768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eb0569-4a1b-4c6a-a0f4-53821ab9f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caafe426-4246-427c-92e9-304d9a0d6770",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optimizer, loss_func, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0aa78d-94fe-406d-8cd1-cd754560ff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf112a2a-1027-431f-9e30-351f99f46a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_func, num_epochs=10, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=3e-4)\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for xb, yb in train_dl:\n",
    "            pred = model(xb.to(device))\n",
    "            loss = loss_func(pred.cpu(), yb)\n",
    "    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "def test(model, device='cuda'):\n",
    "    model.eval()\n",
    "    accuracies = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_dl:\n",
    "            pred = model(xb.to(device))\n",
    "            accuracies.append((pred.cpu().argmax(axis=1) == yb).float().mean().item())\n",
    "    print(f'Accuracy на валидации: {torch.mean(torch.as_tensor(accuracies)):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbba4dc1-7439-43b3-af14-6724d5b41443",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fb59cd-72e0-4c61-9306-ca1c1445129c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb4d483-0629-4c74-9f59-f5bbc1400123",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Transfer learning через timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed46fb-8144-4448-a501-c37ac718afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c004ab7a-7319-4f56-8d81-97686c2d05b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('eca_nfnet_l1', pretrained=True, num_classes=10, in_chans=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1420609-5f2d-42c7-b531-292f9458b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, loss_func, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f3232f-cc65-4927-a3b5-01c55598a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e384d16b-a285-4c6e-be84-97cc252ce427",
   "metadata": {},
   "source": [
    "## Автоэнкодеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba76be6-40ed-430a-8cbb-88250a9d3297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b07196-78e9-4230-b39f-b0d06358a95f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def fetch_dataset(attrs_name = \"lfw_attributes.txt\",\n",
    "                      images_name = \"lfw-deepfunneled\",\n",
    "                      dx=80,dy=80,\n",
    "                      dimx=64,dimy=64\n",
    "    ):\n",
    "\n",
    "    #download if not exists\n",
    "    if not os.path.exists(images_name):\n",
    "        print(\"images not found, donwloading...\")\n",
    "        os.system(\"wget http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz -O tmp.tgz\")\n",
    "        print(\"extracting...\")\n",
    "        os.system(\"tar xvzf tmp.tgz && rm tmp.tgz\")\n",
    "        print(\"done\")\n",
    "        assert os.path.exists(images_name)\n",
    "\n",
    "    if not os.path.exists(attrs_name):\n",
    "        print(\"attributes not found, downloading...\")\n",
    "        os.system(\"wget http://www.cs.columbia.edu/CAVE/databases/pubfig/download/%s\" % attrs_name)\n",
    "        print(\"done\")\n",
    "\n",
    "    #read attrs\n",
    "    df_attrs = pd.read_csv(\"lfw_attributes.txt\",sep='\\t',skiprows=1,) \n",
    "    df_attrs = pd.DataFrame(df_attrs.iloc[:,:-1].values, columns = df_attrs.columns[1:])\n",
    "\n",
    "\n",
    "    #read photos\n",
    "    photo_ids = []\n",
    "    for dirpath, dirnames, filenames in os.walk(images_name):\n",
    "        for fname in filenames:\n",
    "            if fname.endswith(\".jpg\"):\n",
    "                fpath = os.path.join(dirpath,fname)\n",
    "                photo_id = fname[:-4].replace('_',' ').split()\n",
    "                person_id = ' '.join(photo_id[:-1])\n",
    "                photo_number = int(photo_id[-1])\n",
    "                photo_ids.append({'person':person_id,'imagenum':photo_number,'photo_path':fpath})\n",
    "\n",
    "    photo_ids = pd.DataFrame(photo_ids)\n",
    "    # print(photo_ids)\n",
    "    #mass-merge\n",
    "    #(photos now have same order as attributes)\n",
    "    df = pd.merge(df_attrs,photo_ids,on=('person','imagenum'))\n",
    "\n",
    "    assert len(df)==len(df_attrs),\"lost some data when merging dataframes\"\n",
    "\n",
    "    # print(df.shape)\n",
    "    #image preprocessing\n",
    "    all_photos =df['photo_path'].apply(skimage.io.imread)\\\n",
    "                                .apply(lambda img:img[dy:-dy,dx:-dx])\\\n",
    "                                .apply(lambda img: skimage.transform.resize(img,[dimx,dimy]))\n",
    "\n",
    "    all_photos = np.stack(all_photos.values)#.astype('uint8')\n",
    "    all_attrs = df.drop([\"photo_path\",\"person\",\"imagenum\"],axis=1)\n",
    "    \n",
    "    return all_photos, all_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdd8c57-aaea-4651-b2b9-181f4748f72e",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data, attrs = fetch_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55df99c-b959-4c48-94dd-ef3d01411bec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in attrs.columns:\n",
    "    attrs[column] = pd.to_numeric(attrs[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c91d2-ef59-4894-9ede-04036fbe53dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7405c78-0467-47b5-8353-344570fcfd86",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = TensorDataset(torch.from_numpy(data).permute(0, 3, 1, 2).float())\n",
    "train_set, test_set = random_split(dataset, [0.8, 0.2], generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd464c51-dbb8-4933-97dd-13e45bef53fc",
   "metadata": {},
   "source": [
    "### Самостоятельная работа"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1d5cff-80a3-4879-8278-fafb71405862",
   "metadata": {},
   "source": [
    "Создайте даталоадеры для обучающей и тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37c31fe-a0fe-47a3-a54b-6d2fc32de785",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dl = \n",
    "test_dl = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a349f43f-6ed9-48b4-952f-690bc9af201f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(8,4))\n",
    "\n",
    "batch = next(iter(train_dl))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(batch[0][i].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18fc763-ea05-4ac4-87e3-d9a8128b0f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611598a0-2ed3-4c40-99e7-3a28f85842e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size=64, input_channels=3, latent_size=LATENT_SIZE):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 4, 3, padding=1, stride=2, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.Conv2d(4, 16, 3, padding=1, stride=2, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear((input_size)**2, latent_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(latent_size),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_size, input_size**2),\n",
    "            nn.ReLU(),\n",
    "            #nn.BatchNorm1d(input_size**2),\n",
    "            nn.Unflatten(1, torch.Size([16, input_size//4, input_size//4])),\n",
    "            nn.ConvTranspose2d(16, 4, 4, stride=2, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ConvTranspose2d(4, input_channels, 4, stride=2, padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent_code = self.encoder(x)\n",
    "        reconstruction = self.decoder(latent_code)\n",
    "        return reconstruction, latent_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4580bfa6-340a-40fa-a4c5-621bf5764af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "optimizer = Adam(model.parameters(), lr=3e-4)\n",
    "torchinfo.summary(model, input_size=(1, 3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08ec895-f175-465a-b82e-f97fb6794af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bd26c0-bb4a-4e91-b2db-01d31edcb598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ab9bec-d0ff-4ec0-b2c9-081127edda70",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, opt, loss_fn, epochs, data_tr, data_val, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print('* Epoch %d/%d' % (epoch + 1, epochs))\n",
    "\n",
    "        model.train()\n",
    "        avg_loss = 0\n",
    "        for batch in data_tr:\n",
    "            opt.zero_grad()\n",
    "            X = torch.as_tensor(batch[0]).to(device)\n",
    "            reconstruction, vector = model(X)\n",
    "            loss = loss_fn(reconstruction, X)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            avg_loss += loss / len(data_tr)\n",
    "        train_loss.append(avg_loss.detach().cpu())\n",
    "\n",
    "        model.eval()\n",
    "        avg_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in data_val:\n",
    "                X = torch.as_tensor(batch[0]).to(device)\n",
    "                reconstruction, vector = model(X)\n",
    "                loss = loss_fn(reconstruction, X)\n",
    "                avg_loss += loss / len(data_val)\n",
    "        val_loss.append(avg_loss.detach().cpu())\n",
    "    \n",
    "        # Visualize\n",
    "        clear_output(wait=True)\n",
    "        for k in range(5):\n",
    "            plt.subplot(3, 5, k+1)\n",
    "            plt.imshow(torch.as_tensor(batch[0])[k].permute(1, 2, 0))\n",
    "            plt.title('Real')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(3, 5, k+6)\n",
    "            plt.imshow(reconstruction[k].cpu().permute(1, 2, 0))\n",
    "            plt.title('Output')\n",
    "            plt.axis('off')\n",
    "            \n",
    "        plt.suptitle('%d / %d - loss: %f' % (epoch+1, epochs, avg_loss))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a5db6-8757-4c34-a2cd-1f7aee8cac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optimizer, criterion, 50, train_dl, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7ec73-a0e9-438a-9dc3-ad5a8c9cfda6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_a = TensorDataset(torch.from_numpy(data[attrs['Smiling'] > 0.75]).permute(0, 3, 1, 2).float())\n",
    "set_b = TensorDataset(torch.from_numpy(data[attrs['Smiling'] < 1]).permute(0, 3, 1, 2).float())\n",
    "\n",
    "loader_a = DataLoader(set_a, batch_size=256, shuffle=True, num_workers=12)\n",
    "loader_b = DataLoader(set_b, batch_size=256, shuffle=False, num_workers=12)\n",
    "\n",
    "faces_a, vectors_a = model(next(iter(loader_a))[0].to('cuda'))\n",
    "faces_b, vectors_b = model(next(iter(loader_b))[0].to('cuda'))\n",
    "\n",
    "mean_vector_a = torch.mean(vectors_a, dim=0) - torch.mean(vectors_b, dim=0)\n",
    "new_faces = model.decoder(vectors_b + mean_vector_a)\n",
    "\n",
    "fig, axes = plt.subplots(1, 15, figsize=(20,2))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(faces_b[i].permute(1, 2, 0).cpu().detach().numpy())\n",
    "    \n",
    "fig, axes = plt.subplots(1, 15, figsize=(20,2))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(new_faces[i].permute(1, 2, 0).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e1db12-9925-4f26-9e50-0d1c2a46e01a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b25fd-0291-4b4c-8181-b9ab5ae07eb5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = MNIST('mnist-data', download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb314329-7f52-4b0c-87dc-52765f3e5aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = random_split(dataset, [0.8, 0.2], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff944f-ceda-450a-9249-88533caf6292",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=12)\n",
    "test_dl = DataLoader(test_set, batch_size=64, shuffle=False, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b7d5bf-c42e-419e-9cc6-a6f34eeb875b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_size=28, input_channels=1, latent_size=LATENT_SIZE):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 4, 3, padding=1, stride=2, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.Conv2d(4, 16, 3, padding=1, stride=2, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_size**2, latent_size*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(latent_size*2),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_size, input_size**2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.BatchNorm1d(input_size**2),\n",
    "            nn.Unflatten(1, torch.Size([16, input_size//4, input_size//4])),\n",
    "            nn.ConvTranspose2d(16, 4, 4, stride=2, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ConvTranspose2d(4, input_channels, 4, stride=2, padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.latent_size = latent_size\n",
    "    \n",
    "    def forward(self, x):\n",
    "        shapes = x.shape\n",
    "        mu, logsigma = self.encode(x)\n",
    "        sample = self.gaussian_sampler(mu, logsigma)\n",
    "        reconstruction = self.decode(sample)\n",
    "        return mu, logsigma, reconstruction\n",
    "        \n",
    "    def encode(self, x):\n",
    "        return torch.split(self.encoder(x), self.latent_size, dim=1)\n",
    "    \n",
    "    def gaussian_sampler(self, mu, logsigma):\n",
    "        if self.training:\n",
    "            # латентный вектор из нормального распределения с параметрами mu и sigma\n",
    "            return torch.randn_like(logsigma) * torch.exp(logsigma) + mu\n",
    "        else:\n",
    "            # на инференсе возвращаем не случайный вектор из нормального распределения, а центральный -- mu. \n",
    "            # на инференсе выход автоэнкодера должен быть детерминирован.\n",
    "            return mu\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914b7fd5-52ea-40c7-b7ce-6bbf4df33950",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def KL_divergence(mu, logsigma):\n",
    "    \"\"\"\n",
    "    часть функции потерь, которая отвечает за \"близость\" латентных представлений разных людей\n",
    "    \"\"\"\n",
    "    loss = -0.5 * torch.sum(1 + logsigma - mu ** 2 - torch.exp(logsigma))\n",
    "    return loss\n",
    "\n",
    "def log_likelihood(x, reconstruction):\n",
    "    \"\"\"\n",
    "    часть функции потерь, которая отвечает за качество реконструкции (как mse в обычном autoencoder)\n",
    "    \"\"\"\n",
    "    # Чтобы компоненты были соразмерны, понадобится либо reduction='sum' здесь, либо весовой коэффициент ниже:\n",
    "    loss = torch.nn.BCELoss(reduction='sum')\n",
    "    return loss(reconstruction, x)\n",
    "\n",
    "def loss_vae(x, mu, logsigma, reconstruction, kl_weight=1.0):\n",
    "    return kl_weight * KL_divergence(mu, logsigma) + log_likelihood(x, reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589547e0-ca0f-4d14-adcb-674c73de4b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_vae\n",
    "model = VAE()\n",
    "optimizer = Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a101b5-9398-4251-b7c4-43b525958287",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, opt, loss_fn, epochs, data_tr, data_val, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print('* Epoch %d/%d' % (epoch + 1, epochs))\n",
    "\n",
    "        model.train()\n",
    "        avg_loss = 0\n",
    "        for X, y in data_tr:\n",
    "            opt.zero_grad()\n",
    "            mu, logsigma, reconstruction = model(X.to(device))\n",
    "            loss = loss_fn(X.to(device), mu, logsigma, reconstruction)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            avg_loss += loss / len(data_tr)\n",
    "        train_loss.append(avg_loss.detach().cpu())\n",
    "\n",
    "        model.eval()\n",
    "        avg_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in data_val:\n",
    "                mu, logsigma, reconstruction = model(X.to(device))\n",
    "                loss = loss_fn(X.to(device), mu, logsigma, reconstruction)\n",
    "                avg_loss += loss / len(data_val)\n",
    "        val_loss.append(avg_loss.detach().cpu())\n",
    "    \n",
    "        # Visualize\n",
    "        clear_output(wait=True)\n",
    "        for k in range(5):\n",
    "            plt.subplot(3, 5, k+1)\n",
    "            plt.imshow(X[k].cpu().permute(1, 2, 0))\n",
    "            plt.title('Real')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(3, 5, k+6)\n",
    "            plt.imshow(reconstruction[k].cpu().permute(1, 2, 0))\n",
    "            plt.title('Output')\n",
    "            plt.axis('off')\n",
    "            \n",
    "        plt.suptitle('%d / %d - loss: %f' % (epoch+1, epochs, avg_loss))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17e01a-d82b-43f9-bc78-26a859b0dbcc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(model, optimizer, loss_func, 25, train_dl, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81a42d1-6f80-46fd-88e3-72383fbb0025",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mu, logsigma = model.encode(next(iter(test_dl))[0].to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dddc38c-c9b6-4894-bd26-ce6f9ec3c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сгенерируем 32 рандомных вектора размера latent_space\n",
    "z = torch.randn(batch_size, LATENT_SIZE).to('cuda') * torch.exp(logsigma) + mu\n",
    "output = model.decode(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52541d2-a57f-4fa0-a7d7-17d877d7230d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 8, figsize=(8,4))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(output[i].permute(1, 2, 0).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee901eb-8b72-4ac1-b095-491642edfcfc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf995ff-4685-4499-8d18-a7219146d784",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def redux(model, dataloader):\n",
    "    mus = []\n",
    "    sigmas = []\n",
    "    y = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch = X_batch.to('cuda')\n",
    "            mu, logsigma = model.encode(X_batch)\n",
    "            mus.append(mu.cpu())\n",
    "            sigmas.append(logsigma.cpu())\n",
    "            y.extend(y_batch)\n",
    "    \n",
    "    features1 = np.vstack(mus)\n",
    "    features2 = np.vstack(sigmas)\n",
    "    features = np.hstack([features1, features2])\n",
    "    y = np.array(y)\n",
    "    \n",
    "    points = TSNE(2,  metric='cosine', n_jobs=-1, random_state=177013).fit_transform(features)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for digit in range(10):\n",
    "        plt.scatter(points[y==digit][:, 0], points[y==digit][:, 1], marker=f'${digit}$', alpha=0.3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a671462-de11-49af-aa6b-2574e072c555",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "redux(model, test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533b5b76-5a70-4149-ad08-242b0c35fda4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded8e5f1-7669-4430-a136-6b649c1ed53d",
   "metadata": {},
   "source": [
    "## Easy/Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f342895-e8de-4804-8c59-4f3b6438c6f0",
   "metadata": {},
   "source": [
    "Построим модель регрессии на базе полносвязной сети. Превратить датафрейм pandas в тензоры можно, например, вот так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077cf1b2-54cf-4c62-8e2f-c629417bf07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/home/daiyousei/Concrete_Data.xls', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679fee32-836c-4ff0-a8b5-39ee2a8606b9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b3004-6e21-4d43-9cef-77ceac3492dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.rename(lambda x: x.split('(')[0].strip().replace(' ', '_').lower(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02227e3d-007e-44b3-9609-017e17f2eff2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = torch.as_tensor(df.drop(['concrete_compressive_strength'], axis=1).values, dtype=torch.float32)\n",
    "y = torch.as_tensor(df['concrete_compressive_strength'].values.reshape(-1,1), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930fb3dd-8625-4c7b-aa3d-5b10bd493004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# То же, что делает StandardScaler():\n",
    "standardized_data = (X - torch.mean(X, dim=0)) / torch.std(X, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6d4f9c-17de-4a13-9d7b-74db83ef5f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TensorDataset(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b6ce06-3fd6-4eb9-a691-613d304b1d68",
   "metadata": {},
   "source": [
    "Кроме того, вы можете попробовать `torch.utils.data.datapipes.CsvLoader()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb080ae6-187c-4e67-9320-624977eaceee",
   "metadata": {},
   "source": [
    "Выделите обучающую и тестовую выборки с помощью `torch.utils.data.random_split()`. Создайте даталоадеры для них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba90528-6fcc-451c-aea7-8a5bc520bb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da864e6f-2aeb-42b6-9366-ed13fc807235",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = ...\n",
    "test_dl = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3b4f44-c2c9-42f6-a677-690a56a78c2d",
   "metadata": {},
   "source": [
    "Допишите полносвязную сеть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba0f774-6add-49b5-9532-dd3ea6df80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Ваш код ниже:\n",
    "        \n",
    "\n",
    "    def forward(self, xb):\n",
    "        # Ваш код ниже:\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfb73f6-4a23-4623-8613-9fc3da2bc530",
   "metadata": {},
   "source": [
    "Инициализируем модель. Для регрессии мы будем использовать MSE или MAE(`L1Loss()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8398c900-5942-409b-9ccb-2e32cd308649",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "optimizer = Adam(model.parameters(), lr=0.1)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa536d53-4f8f-4bb9-bbbd-17d458a48dfe",
   "metadata": {},
   "source": [
    "Допишите цикл обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb6e64a-5560-46a2-aab0-c84f343fc934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_func, num_epochs=10):\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for xb, yb in train_dl:\n",
    "            ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06dfdf0-8309-414b-8fd0-bcac3b69d3ca",
   "metadata": {},
   "source": [
    "Вы можете воспользоваться этой функцией для тестирования или модифицировать ее. Попытайтесь подобрать структуру сети и гиперпараметры, чтобы улучшить метрику. Чем больше значимых экспериментов, тем выше будет оценено ваше задание.\n",
    "\n",
    "Если метрика получилась хуже, чем у модели из sklearn, не расстраивайтесь: не везде сложные инструменты дают лучший результат!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28efd0f-7eac-435d-b57d-e7043b72812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_dl:\n",
    "            with torch.no_grad():\n",
    "                pred = model(xb)\n",
    "                mse = loss_func(pred, yb)\n",
    "                losses.append(mse.mean())\n",
    "    print(f'MSE на валидации: {torch.mean(torch.as_tensor(losses)):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74a2910-0724-462a-9aff-301cf9b27179",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optimizer, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b13219-1154-4549-b40a-ca519493e1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24583b4b-1123-492a-a9f4-d25d71e213a8",
   "metadata": {},
   "source": [
    "## Hard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0936b7-c83c-4348-b8bd-1f536be64d4c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Попробуйте реализовать Conditional VAE для MNIST: подавать нейросети на вход не только вектор, но и желаемый класс. То есть из одного вектора модель должна уметь восстановить любую цифру, которую ей укажут.\n",
    "\n",
    "Если вам трудно правильно склеить данные, вы можете попробовать построить все на линейных слоях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c505b476-5ae7-4578-a1f6-c71bc8f77cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0334c2-854d-4a8a-b9ea-b3ffc1ac9c2b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Обучите модель, проверьте генерацию.\n",
    "\n",
    "Исследуйте латентное пространство с помощью понижения размерности. Укажите различия с обычным VAE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
